{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# try:\n",
    "#     os.chdir('workspace')\n",
    "\n",
    "from options import Options\n",
    "opt = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_labels</th>\n",
       "      <th>captionID</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>pairID</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence1_binary_parse</th>\n",
       "      <th>sentence1_parse</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence2_binary_parse</th>\n",
       "      <th>sentence2_parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>4609020271.jpg#3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4609020271.jpg#3r1n</td>\n",
       "      <td>A kid bored in a train with brown hair and his...</td>\n",
       "      <td>( ( A kid ) ( ( bored ( in ( ( ( ( a train ) (...</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN kid)) (VP (VBD bored) ...</td>\n",
       "      <td>A child is riding the train from New York to B...</td>\n",
       "      <td>( ( A child ) ( ( is ( ( riding ( the train ) ...</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN child)) (VP (VBZ is) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
       "      <td>2313230479.jpg#2</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>2313230479.jpg#2r1c</td>\n",
       "      <td>A brown dog and black and white dog run along ...</td>\n",
       "      <td>( ( ( ( A ( brown dog ) ) and ) ( ( ( black an...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (JJ brown) (NN dog)) (...</td>\n",
       "      <td>Two squirrels run after acorns in the grass.</td>\n",
       "      <td>( ( Two squirrels ) ( ( run ( after ( acorns (...</td>\n",
       "      <td>(ROOT (S (NP (CD Two) (NNS squirrels)) (VP (VB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[neutral, contradiction, contradiction, neutra...</td>\n",
       "      <td>3729748378.jpg#1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3729748378.jpg#1r1n</td>\n",
       "      <td>A person in full astronaut suit and gear train...</td>\n",
       "      <td>( ( ( A person ) ( in ( ( full ( astronaut ( s...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN i...</td>\n",
       "      <td>A female astronaut adjusting to the feeling of...</td>\n",
       "      <td>( ( ( A ( female astronaut ) ) ( ( ( adjusting...</td>\n",
       "      <td>(ROOT (NP (NP (DT A) (JJ female) (NN astronaut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[entailment, entailment, contradiction, contra...</td>\n",
       "      <td>4708658738.jpg#0</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>4708658738.jpg#0r1e</td>\n",
       "      <td>An old Indian man dressed in rags sleeps on th...</td>\n",
       "      <td>( ( ( An ( old ( Indian man ) ) ) ( dressed ( ...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT An) (JJ old) (JJ Indian) ...</td>\n",
       "      <td>An old Indian man is dressed up</td>\n",
       "      <td>( ( An ( old ( Indian man ) ) ) ( is ( dressed...</td>\n",
       "      <td>(ROOT (S (NP (DT An) (JJ old) (JJ Indian) (NN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>2372820502.jpg#0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2372820502.jpg#0r1n</td>\n",
       "      <td>A bunch of people are standing all together in...</td>\n",
       "      <td>( ( ( A bunch ) ( of people ) ) ( ( are ( ( st...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (NN bunch)) (PP (IN of...</td>\n",
       "      <td>A group of people are planning something.</td>\n",
       "      <td>( ( ( A group ) ( of people ) ) ( ( are ( plan...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (NN group)) (PP (IN of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    annotator_labels         captionID  \\\n",
       "0      [neutral, neutral, neutral, neutral, neutral]  4609020271.jpg#3   \n",
       "1  [contradiction, contradiction, contradiction, ...  2313230479.jpg#2   \n",
       "2  [neutral, contradiction, contradiction, neutra...  3729748378.jpg#1   \n",
       "3  [entailment, entailment, contradiction, contra...  4708658738.jpg#0   \n",
       "4      [neutral, neutral, neutral, neutral, neutral]  2372820502.jpg#0   \n",
       "\n",
       "      gold_label               pairID  \\\n",
       "0        neutral  4609020271.jpg#3r1n   \n",
       "1  contradiction  2313230479.jpg#2r1c   \n",
       "2        neutral  3729748378.jpg#1r1n   \n",
       "3  contradiction  4708658738.jpg#0r1e   \n",
       "4        neutral  2372820502.jpg#0r1n   \n",
       "\n",
       "                                           sentence1  \\\n",
       "0  A kid bored in a train with brown hair and his...   \n",
       "1  A brown dog and black and white dog run along ...   \n",
       "2  A person in full astronaut suit and gear train...   \n",
       "3  An old Indian man dressed in rags sleeps on th...   \n",
       "4  A bunch of people are standing all together in...   \n",
       "\n",
       "                              sentence1_binary_parse  \\\n",
       "0  ( ( A kid ) ( ( bored ( in ( ( ( ( a train ) (...   \n",
       "1  ( ( ( ( A ( brown dog ) ) and ) ( ( ( black an...   \n",
       "2  ( ( ( A person ) ( in ( ( full ( astronaut ( s...   \n",
       "3  ( ( ( An ( old ( Indian man ) ) ) ( dressed ( ...   \n",
       "4  ( ( ( A bunch ) ( of people ) ) ( ( are ( ( st...   \n",
       "\n",
       "                                     sentence1_parse  \\\n",
       "0  (ROOT (S (NP (DT A) (NN kid)) (VP (VBD bored) ...   \n",
       "1  (ROOT (S (NP (NP (DT A) (JJ brown) (NN dog)) (...   \n",
       "2  (ROOT (S (NP (NP (DT A) (NN person)) (PP (IN i...   \n",
       "3  (ROOT (S (NP (NP (DT An) (JJ old) (JJ Indian) ...   \n",
       "4  (ROOT (S (NP (NP (DT A) (NN bunch)) (PP (IN of...   \n",
       "\n",
       "                                           sentence2  \\\n",
       "0  A child is riding the train from New York to B...   \n",
       "1       Two squirrels run after acorns in the grass.   \n",
       "2  A female astronaut adjusting to the feeling of...   \n",
       "3                    An old Indian man is dressed up   \n",
       "4          A group of people are planning something.   \n",
       "\n",
       "                              sentence2_binary_parse  \\\n",
       "0  ( ( A child ) ( ( is ( ( riding ( the train ) ...   \n",
       "1  ( ( Two squirrels ) ( ( run ( after ( acorns (...   \n",
       "2  ( ( ( A ( female astronaut ) ) ( ( ( adjusting...   \n",
       "3  ( ( An ( old ( Indian man ) ) ) ( is ( dressed...   \n",
       "4  ( ( ( A group ) ( of people ) ) ( ( are ( plan...   \n",
       "\n",
       "                                     sentence2_parse  \n",
       "0  (ROOT (S (NP (DT A) (NN child)) (VP (VBZ is) (...  \n",
       "1  (ROOT (S (NP (CD Two) (NNS squirrels)) (VP (VB...  \n",
       "2  (ROOT (NP (NP (DT A) (JJ female) (NN astronaut...  \n",
       "3  (ROOT (S (NP (DT An) (JJ old) (JJ Indian) (NN ...  \n",
       "4  (ROOT (S (NP (NP (DT A) (NN group)) (PP (IN of...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('original/snli_1.0_test.jsonl', lines=True)\n",
    "df = df.sample(5, random_state=42).reset_index(drop=True)\n",
    "train_df = df\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0,\n",
       " '<pad>': 1,\n",
       " 'a': 2,\n",
       " 'kid': 3,\n",
       " 'bored': 4,\n",
       " 'in': 5,\n",
       " 'train': 6,\n",
       " 'with': 7,\n",
       " 'brown': 8,\n",
       " 'hair': 9,\n",
       " 'and': 10,\n",
       " 'his': 11,\n",
       " 'head': 12,\n",
       " 'lying': 13,\n",
       " 'down': 14,\n",
       " 'dog': 15,\n",
       " 'black': 16,\n",
       " 'white': 17,\n",
       " 'run': 18,\n",
       " 'along': 19,\n",
       " 'the': 20,\n",
       " 'green': 21,\n",
       " 'grass': 22,\n",
       " 'person': 23,\n",
       " 'full': 24,\n",
       " 'astronaut': 25,\n",
       " 'suit': 26,\n",
       " 'gear': 27,\n",
       " 'trains': 28,\n",
       " 'an': 29,\n",
       " 'underwater': 30,\n",
       " 'lab': 31,\n",
       " 'as': 32,\n",
       " 'scuba': 33,\n",
       " 'diver': 34,\n",
       " 'assists': 35,\n",
       " 'old': 36,\n",
       " 'indian': 37,\n",
       " 'man': 38,\n",
       " 'dressed': 39,\n",
       " 'rags': 40,\n",
       " 'sleeps': 41,\n",
       " 'on': 42,\n",
       " 'ground': 43,\n",
       " 'using': 44,\n",
       " 'backpack': 45,\n",
       " 'pillow': 46,\n",
       " 'bunch': 47,\n",
       " 'of': 48,\n",
       " 'people': 49,\n",
       " 'are': 50,\n",
       " 'standing': 51,\n",
       " 'all': 52,\n",
       " 'together': 53,\n",
       " 'street': 54,\n",
       " 'building': 55,\n",
       " 'background': 56,\n",
       " 'child': 57,\n",
       " 'is': 58,\n",
       " 'riding': 59,\n",
       " 'from': 60,\n",
       " 'new': 61,\n",
       " 'york': 62,\n",
       " 'to': 63,\n",
       " 'boston': 64,\n",
       " 'two': 65,\n",
       " 'squirrels': 66,\n",
       " 'after': 67,\n",
       " 'acorns': 68,\n",
       " 'female': 69,\n",
       " 'adjusting': 70,\n",
       " 'feeling': 71,\n",
       " 'low': 72,\n",
       " 'gravity': 73,\n",
       " 'by': 74,\n",
       " 'training': 75,\n",
       " 'up': 76,\n",
       " 'group': 77,\n",
       " 'planning': 78,\n",
       " 'something': 79}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "\n",
    "## Tad bit weird so just change train.py\n",
    "opt.model = \"LSTM\"\n",
    "opt.model_folder = \"models/LSTM_TEST\"\n",
    "opt.data_folder = \"data/LSTM_TEST\"\n",
    "os.makedirs(opt.model_folder, exist_ok=True)\n",
    "os.makedirs(opt.data_folder, exist_ok=True)\n",
    "\n",
    "opt.embedding_dim = 6\n",
    "opt.hidden_dim = 4\n",
    "\n",
    "vocab = create_vocab(train_df, opt)\n",
    "vocab_size = len(vocab)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.save_options(opt.model_folder)\n",
    "\n",
    "word_embeddings = nn.Embedding(vocab_size, opt.embedding_dim)\n",
    "\n",
    "# Replace this line with actual fasttext embeddings\n",
    "pretrained_fasttext_embeddings  = torch.rand((vocab_size, opt.embedding_dim))\n",
    "\n",
    "word_embeddings.weight.data.copy_(pretrained_fasttext_embeddings)\n",
    "torch.save(word_embeddings.state_dict(), f'{opt.data_folder}/word_embeddings.pth')\n",
    "\n",
    "\n",
    "## Init\n",
    "vocab = load_vocab(opt)\n",
    "word_embeddings = nn.Embedding(opt.vocab_size, opt.embedding_dim)\n",
    "word_embeddings.load_state_dict(torch.load(f'{opt.data_folder}/word_embeddings.pth'))\n",
    "\n",
    "\n",
    "# Indexing\n",
    "idx = 0\n",
    "sentence1, sentence2 = df.loc[idx, ['sentence1', 'sentence2']]\n",
    "sentence1, sentence2 = clean_text(sentence1), clean_text(sentence2)\n",
    "\n",
    "y = torch.tensor(le(df.loc[idx, 'gold_label']))\n",
    "\n",
    "input_ids1 = torch.ones(100, dtype=torch.long)\n",
    "input_ids2 = torch.ones(100, dtype=torch.long)\n",
    "\n",
    "for i, word in enumerate(sentence1.split()):\n",
    "    input_ids1[i] = vocab[word] if word in vocab else 0\n",
    "\n",
    "for i, word in enumerate(sentence2.split()):\n",
    "    input_ids2[i] = vocab[word] if word in vocab else 0\n",
    "\n",
    "embeds1, embeds2 = word_embeddings(input_ids1), word_embeddings(input_ids2)\n",
    "X = [embeds1, embeds2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "## Init\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "sentence1 = df['sentence1'].tolist()\n",
    "sentence2 = df['sentence2'].tolist()\n",
    "info = tokenizer(sentence1, sentence2, padding='max_length', max_length=200, return_tensors='pt')\n",
    "\n",
    "input_ids = info['input_ids']\n",
    "attention_mask = info['attention_mask']\n",
    "\n",
    "y = torch.tensor(df['gold_label'].apply(lambda label: le(label)))\n",
    "\n",
    "## Get idx\n",
    "idx = 0\n",
    "input_ids = input_ids[idx]\n",
    "attention_mask = attention_mask[idx]\n",
    "\n",
    "X = [input_ids, attention_mask]\n",
    "y = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0842,  0.0786,  0.0021,  ..., -0.1036, -0.0471, -0.0484],\n",
       "         [-0.1940, -0.0074, -0.1065,  ..., -0.2165, -0.1920,  0.2804],\n",
       "         [ 0.0318,  0.1695,  0.0527,  ..., -0.2234, -0.0391,  0.2766],\n",
       "         ...,\n",
       "         [-0.0612,  0.1395,  0.0673,  ...,  0.0030, -0.0716,  0.0486],\n",
       "         [-0.0612,  0.1395,  0.0673,  ...,  0.0030, -0.0716,  0.0486],\n",
       "         [-0.0612,  0.1395,  0.0673,  ...,  0.0030, -0.0716,  0.0486]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.0102, -0.3253, -0.3312, -0.0306,  0.1273,  0.0639,  0.2021, -0.1914,\n",
       "          0.0785, -0.0135, -0.1918,  0.1519, -0.2244,  0.0356,  0.0155, -0.1790,\n",
       "          0.1750, -0.1291, -0.3025,  0.1235, -0.1557,  0.2749, -0.0383,  0.2314,\n",
       "          0.2830,  0.1122, -0.1597, -0.1980, -0.1307, -0.4829, -0.5255, -0.4683,\n",
       "         -0.0761, -0.0545,  0.0817, -0.5690, -0.4173,  0.1060,  0.0903,  0.2968,\n",
       "         -0.1599, -0.1793,  0.3524, -0.1011, -0.0632,  0.0332, -0.4141, -0.1479,\n",
       "          0.0973,  0.1620, -0.4000, -0.0234, -0.2500,  0.2561,  0.0973, -0.1083,\n",
       "         -0.2675, -0.2466,  0.0854, -0.1060,  0.0818, -0.0642, -0.1234,  0.3014,\n",
       "          0.2198,  0.4148, -0.3012,  0.0814,  0.4083,  0.2418, -0.1831, -0.0239,\n",
       "          0.1940, -0.0050,  0.1024, -0.3565, -0.1799, -0.0573, -0.0794,  0.2042,\n",
       "          0.4759,  0.0378,  0.1692, -0.4910,  0.4101,  0.1898, -0.0288,  0.1159,\n",
       "          0.1547, -0.3099,  0.0943,  0.3973, -0.6323,  0.0511, -0.2782, -0.1153,\n",
       "         -0.3414,  0.3151, -0.3480,  0.1140, -0.3977,  0.1795, -0.1137,  0.3901,\n",
       "         -0.3876, -0.0263,  0.0620,  0.5732,  0.1232, -0.5189,  0.2249, -0.4063,\n",
       "          0.1186,  0.0898, -0.1078, -0.3173,  0.1236,  0.0551,  0.0133, -0.0817,\n",
       "          0.0694, -0.0238,  0.0742,  0.1002, -0.3651,  0.0216,  0.1530,  0.3330,\n",
       "         -0.1194,  0.1661, -0.4001,  0.1477, -0.3258,  0.1402, -0.2523,  0.0051,\n",
       "         -0.2361, -0.0283,  0.2529,  0.1202, -0.1525,  0.1728, -0.2119,  0.1848,\n",
       "         -0.1279,  0.0017, -0.0041, -0.4350,  0.0712, -0.3283,  0.1196,  0.2508,\n",
       "         -0.1233,  0.0256, -0.1352,  0.2433, -0.2276, -0.1122, -0.1502, -0.2060,\n",
       "          0.1162,  0.0065, -0.1843,  0.2559,  0.3173, -0.3339, -0.3228,  0.1817,\n",
       "          0.2722,  0.0812,  0.0736, -0.5249,  0.0912,  0.2239, -0.1963, -0.1034,\n",
       "         -0.3134, -0.0990, -0.2671, -0.3804, -0.0676, -0.1142, -0.0956, -0.0702,\n",
       "         -0.0593,  0.2362, -0.1476,  0.2987,  0.0859,  0.0759,  0.0088,  0.3177,\n",
       "          0.1972,  0.0345,  0.1157, -0.0901, -0.0523,  0.1655, -0.1554,  0.0649,\n",
       "          0.3556, -0.3022,  0.0335,  0.0955, -0.0634, -0.2318,  0.0076, -0.1887,\n",
       "         -0.4831, -0.2266,  0.0135, -0.1501, -0.0280, -0.0399, -0.1963, -0.0289,\n",
       "         -0.3781,  0.5913,  0.1212, -0.1077, -0.1894, -0.2958,  0.0017,  0.3125,\n",
       "          0.4833, -0.2103, -0.0555,  0.0734, -0.1065, -0.2936,  0.3826,  0.1803,\n",
       "         -0.0079,  0.2840, -0.1023,  0.1102, -0.2165, -0.1072,  0.2671,  0.1879,\n",
       "          0.1317,  0.0186, -0.4518,  0.2074, -0.0616, -0.1892, -0.3020,  0.2473,\n",
       "         -0.1544, -0.3147,  0.2373, -0.2599,  0.3372,  0.0246, -0.0343,  0.4604,\n",
       "          0.0219,  0.1192, -0.1394, -0.0404, -0.2215,  0.1673,  0.0091, -0.1195,\n",
       "         -0.1325,  0.1573,  0.2174,  0.2706,  0.1887,  0.3619, -0.2770,  0.0166,\n",
       "         -0.5821,  0.1321, -0.0967,  0.3491,  0.0299,  0.0832,  0.1928,  0.2893,\n",
       "         -0.1730, -0.0239, -0.1689,  0.2534, -0.0157, -0.3045, -0.2692, -0.1075,\n",
       "         -0.4065, -0.1198,  0.1580, -0.3015,  0.2757, -0.0314,  0.1580, -0.2625,\n",
       "          0.4213,  0.5076,  0.0204, -0.1671,  0.3801,  0.0789,  0.0527,  0.1563,\n",
       "         -0.0936, -0.1140, -0.0197, -0.1671, -0.4970,  0.2093, -0.1160, -0.2278,\n",
       "          0.2042,  0.2992,  0.2896,  0.1350, -0.1861,  0.1546,  0.3225,  0.1840,\n",
       "          0.1371, -0.2360, -0.2285,  0.0435, -0.2085,  0.2387, -0.4125,  0.2341,\n",
       "         -0.2702, -0.2930,  0.1915,  0.3444, -0.0559,  0.0778,  0.1524,  0.0734,\n",
       "         -0.1420,  0.1939,  0.2773, -0.1953, -0.0230,  0.1303,  0.2941,  0.0446,\n",
       "         -0.0417, -0.1978,  0.0718,  0.1842, -0.3117, -0.0265, -0.0192,  0.2024,\n",
       "          0.0925, -0.0226, -0.0871,  0.2270,  0.0971,  0.4160, -0.1282,  0.0731,\n",
       "          0.1041, -0.0212,  0.2757,  0.1690, -0.0684, -0.1985,  0.3056, -0.3376,\n",
       "          0.1948, -0.3855, -0.1719, -0.3772,  0.2241,  0.2872, -0.0920, -0.1036,\n",
       "          0.0102,  0.0768, -0.3270, -0.1213,  0.0323,  0.0104, -0.0044, -0.0882,\n",
       "         -0.0049, -0.0886, -0.2717, -0.0786,  0.2538,  0.2340, -0.1670,  0.1796,\n",
       "          0.4691, -0.0452, -0.6782, -0.1323,  0.4334,  0.1297, -0.2774, -0.1316,\n",
       "          0.2400, -0.1171, -0.1619, -0.2236,  0.0354, -0.1336, -0.4041,  0.2070,\n",
       "          0.0329, -0.3552, -0.2530,  0.0839,  0.1383,  0.4218, -0.0874, -0.2702,\n",
       "         -0.1686,  0.4267, -0.3780, -0.1744,  0.1948,  0.1457,  0.1496,  0.2841,\n",
       "          0.1989,  0.0691, -0.1560,  0.1312, -0.3412,  0.2898,  0.4642, -0.3048,\n",
       "         -0.2233,  0.1809,  0.2589,  0.2482, -0.1513, -0.1844,  0.3110,  0.0765,\n",
       "          0.1220,  0.3302, -0.2190,  0.0761,  0.1071, -0.0943,  0.2675,  0.3596,\n",
       "         -0.2642, -0.0048, -0.2069, -0.0632, -0.0438, -0.0433,  0.4160,  0.3122,\n",
       "         -0.0825, -0.0402,  0.0920,  0.0626,  0.0774, -0.2643,  0.0285,  0.1742,\n",
       "          0.0949, -0.1509,  0.2504, -0.3184, -0.2018,  0.4976, -0.2237, -0.1173,\n",
       "         -0.1492,  0.0574,  0.1988, -0.1840,  0.0777,  0.3802,  0.1913,  0.3491,\n",
       "          0.1648,  0.4995, -0.4056,  0.1946,  0.1957, -0.3684, -0.0316,  0.1851,\n",
       "          0.1312, -0.0107,  0.2099, -0.2939, -0.0260, -0.0401, -0.2045,  0.2232,\n",
       "          0.4216, -0.1087,  0.2740,  0.0112, -0.1754,  0.0156, -0.1977, -0.5401,\n",
       "          0.0241,  0.0803,  0.2337, -0.1114,  0.2831,  0.1456,  0.0714,  0.0320,\n",
       "          0.2838, -0.1697, -0.2255, -0.0028, -0.1710, -0.0093,  0.1078,  0.1587,\n",
       "          0.0922, -0.4003, -0.0930,  0.0361, -0.1806,  0.2761,  0.1770, -0.3544,\n",
       "          0.0627,  0.1550, -0.2675,  0.1053,  0.2273, -0.1391,  0.1118,  0.3095,\n",
       "          0.4186, -0.0074, -0.2270,  0.1767,  0.0844,  0.2560, -0.1990,  0.0176,\n",
       "          0.1543, -0.0715,  0.1362,  0.0325, -0.1676, -0.0880,  0.2626, -0.1394,\n",
       "         -0.0695, -0.2099, -0.3350,  0.2564, -0.1725, -0.2329,  0.0871, -0.1727,\n",
       "         -0.2766, -0.0313,  0.1194, -0.2179, -0.3044,  0.0441, -0.1316, -0.3965,\n",
       "         -0.0605, -0.2035,  0.2892,  0.2531,  0.0606,  0.0256, -0.2696,  0.4016,\n",
       "          0.0387,  0.1221, -0.1123, -0.0608,  0.4037,  0.0579,  0.1159,  0.2009,\n",
       "          0.1118,  0.3356, -0.0687,  0.0741,  0.3245,  0.1875,  0.2592,  0.0324,\n",
       "          0.1693,  0.2800,  0.2578,  0.0483, -0.2277, -0.0046, -0.1910, -0.2452,\n",
       "          0.0220, -0.3357,  0.0013, -0.0670,  0.0272, -0.1726, -0.0773, -0.2124,\n",
       "          0.0644,  0.2296,  0.0195,  0.2970,  0.0794,  0.1097, -0.0335,  0.1530,\n",
       "          0.1783,  0.1124,  0.3328, -0.1562,  0.1297, -0.0207, -0.0170,  0.1874,\n",
       "          0.4031, -0.0776,  0.1077, -0.3232,  0.2645, -0.1142, -0.1515, -0.0812,\n",
       "         -0.0988, -0.0456,  0.0134,  0.0613,  0.3747, -0.1111, -0.0022,  0.0056,\n",
       "         -0.2956, -0.1453,  0.0990,  0.1062, -0.0757,  0.1299,  0.2240, -0.0516,\n",
       "          0.1861,  0.0314, -0.3214,  0.1053,  0.3377, -0.1118, -0.3509, -0.2412,\n",
       "          0.1811, -0.1635,  0.0484, -0.0137,  0.2416,  0.3083,  0.0199, -0.1567,\n",
       "         -0.0559,  0.2514, -0.1068, -0.3028,  0.2049, -0.2724,  0.0048,  0.1294,\n",
       "          0.0270, -0.2518,  0.0916,  0.0796,  0.2317,  0.3042, -0.1179, -0.0140,\n",
       "         -0.3937, -0.0025, -0.0926,  0.3091,  0.1928,  0.1352,  0.1237, -0.0615,\n",
       "          0.3382,  0.0436,  0.3627, -0.1365,  0.1905, -0.1014, -0.1628, -0.0826,\n",
       "         -0.0282,  0.0801,  0.0443, -0.5189,  0.1890,  0.0736,  0.1387,  0.0309,\n",
       "          0.0385, -0.2494,  0.2194,  0.1489, -0.3249, -0.0062, -0.2668,  0.1109,\n",
       "          0.1061, -0.1705, -0.2327,  0.0300,  0.1554,  0.1748, -0.4335, -0.2819,\n",
       "         -0.0458, -0.0468,  0.3001, -0.1893,  0.2185,  0.2750,  0.0648,  0.1603,\n",
       "         -0.1103, -0.3772, -0.1245, -0.2504,  0.0851, -0.0428,  0.2649, -0.3791,\n",
       "         -0.4900,  0.2353,  0.2833,  0.3216,  0.2283, -0.1683, -0.0456,  0.2411,\n",
       "          0.2366, -0.2927,  0.2444, -0.1980, -0.1491,  0.1819,  0.4642,  0.0183,\n",
       "         -0.1145,  0.2329,  0.0091,  0.3108, -0.1859, -0.1768,  0.0868,  0.3196,\n",
       "         -0.0212,  0.1348,  0.1040,  0.6818,  0.0151,  0.0908, -0.0830,  0.1156]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [x.view(1,*x.shape) for x in X]\n",
    "y = y.view(1)\n",
    "from transformers import RobertaModel\n",
    "bert = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "input_ids, attention_mask = X\n",
    "out = bert(input_ids, attention_mask = attention_mask)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\statix/.cache\\torch\\hub\\huggingface_pytorch-transformers_main\n",
      "c:\\Users\\statix\\miniconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "\n",
    "## Init\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')\n",
    "sentence1 = df['sentence1'].tolist()\n",
    "sentence2 = df['sentence2'].tolist()\n",
    "info = tokenizer(sentence1, sentence2, padding='max_length', max_length=200, return_tensors='pt')\n",
    "\n",
    "input_ids = info['input_ids']\n",
    "token_type_ids = info['token_type_ids']\n",
    "attention_mask = info['attention_mask']\n",
    "\n",
    "y = torch.tensor(df['gold_label'].apply(lambda label: le(label)))\n",
    "\n",
    "\n",
    "## Get idx\n",
    "idx = 0\n",
    "input_ids = input_ids[idx]\n",
    "token_type_ids = token_type_ids[idx]\n",
    "attention_mask = attention_mask[idx]\n",
    "\n",
    "X = [input_ids, token_type_ids, attention_mask]\n",
    "y = y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x.view(1,*x.shape) for x in X]\n",
    "y = y.view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [torch.randn(30,*x.shape) for x in X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(opt.embedding_dim, opt.hidden_dim, batch_first=True, bidirectional=True)\n",
    "embeds1, embeds2 = X\n",
    "\n",
    "out1, (h, c) = lstm(embeds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 8])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward and backward concatenated\n",
    "out1[:, -1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 4])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward and backward not concatenated\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0512,  0.0485, -0.2428,  0.0412,  0.1431,  0.1300, -0.1976, -0.0655],\n",
       "        [-0.2403,  0.1184, -0.3530,  0.2882,  0.0499, -0.0162, -0.0347, -0.1560],\n",
       "        [-0.1178, -0.0512, -0.3399,  0.1470, -0.0422,  0.0048,  0.0779, -0.1458],\n",
       "        [-0.0479,  0.1407, -0.0342, -0.0346,  0.0566,  0.0123, -0.2221,  0.0120],\n",
       "        [-0.2458,  0.1486, -0.1870,  0.1065,  0.0017, -0.1152, -0.2017, -0.2473],\n",
       "        [-0.1424, -0.0145, -0.2297, -0.1777,  0.0283,  0.0373, -0.0799, -0.1652],\n",
       "        [-0.0780,  0.1414, -0.0921, -0.2335,  0.0792,  0.0506,  0.0436, -0.1143],\n",
       "        [-0.0976, -0.0558,  0.2510, -0.2692,  0.0132, -0.0167,  0.0125, -0.2026],\n",
       "        [-0.0247,  0.0237, -0.2977,  0.0070,  0.0519,  0.0352, -0.0099, -0.1840],\n",
       "        [-0.0364,  0.0998, -0.2174,  0.1123,  0.0827,  0.1107, -0.3111,  0.1549],\n",
       "        [-0.1475,  0.1525, -0.2729,  0.1515,  0.0743, -0.0374, -0.1184, -0.1717],\n",
       "        [-0.0825,  0.5651, -0.2147,  0.0653,  0.0875, -0.0460,  0.0120, -0.2157],\n",
       "        [ 0.0415,  0.2617,  0.0178,  0.0119,  0.0806, -0.0728, -0.0781, -0.2479],\n",
       "        [-0.0678,  0.1466, -0.0872,  0.0009,  0.1128, -0.0884, -0.1228, -0.1583],\n",
       "        [-0.0539,  0.0638, -0.3189,  0.1175,  0.0290,  0.0341, -0.1013, -0.2492],\n",
       "        [-0.2384,  0.0619, -0.1704, -0.2634,  0.0448,  0.0340,  0.0355, -0.2318],\n",
       "        [-0.1143,  0.1827, -0.2164,  0.1897,  0.1308,  0.0348, -0.1750,  0.1181],\n",
       "        [ 0.0263,  0.3750, -0.1433,  0.0508,  0.0808, -0.0860,  0.0447, -0.3069],\n",
       "        [-0.1767,  0.0225, -0.2979,  0.0068,  0.0400,  0.0274, -0.1371, -0.2644],\n",
       "        [-0.0843,  0.0735,  0.0149,  0.0705,  0.0683,  0.0988, -0.2928, -0.0424],\n",
       "        [-0.2577, -0.0941, -0.3801,  0.0260, -0.0557, -0.0143,  0.0627, -0.1603],\n",
       "        [-0.2911,  0.0223, -0.2814,  0.3869,  0.0288, -0.0892, -0.0527, -0.0502],\n",
       "        [-0.3015,  0.0695, -0.5164, -0.0655, -0.0979,  0.0014,  0.0975, -0.2659],\n",
       "        [-0.2606,  0.1330,  0.0168, -0.2089, -0.0341,  0.0014,  0.1243, -0.2449],\n",
       "        [-0.1796,  0.3120,  0.2314,  0.1072,  0.0508, -0.0799, -0.1293, -0.0306],\n",
       "        [-0.0082,  0.1084,  0.3904,  0.0733,  0.0040, -0.1150, -0.3038, -0.3056],\n",
       "        [ 0.1292,  0.1819, -0.2703,  0.1309,  0.1356,  0.0592, -0.1862, -0.0700],\n",
       "        [-0.1236,  0.3538,  0.0240,  0.0078,  0.0695, -0.0472, -0.1716, -0.1240],\n",
       "        [ 0.1822,  0.2065, -0.1030,  0.1940,  0.1188, -0.0027, -0.2233,  0.3806],\n",
       "        [ 0.1059,  0.2634, -0.0492, -0.1512,  0.0286,  0.0523,  0.0732, -0.3363]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the last vector as sentence representation\n",
    "out1[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\statix/.cache\\torch\\hub\\huggingface_pytorch-transformers_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1687,  1.4565, -0.5958]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "\n",
    "\n",
    "bert = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')\n",
    "linear = nn.Linear(768, 3)\n",
    "\n",
    "input_ids, token_type_ids, attention_mask = X\n",
    "\n",
    "out = bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "\n",
    "out = out[1] # CLS representation of both sentences\n",
    "out = linear(out)  # Cross-Entropy Loss takes in the unnormalized logits\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
